{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SahilBhutani09/Sahil-Assignments/blob/main/Marketing%20Mix%20Analysis/MMM_Model_Bayesian.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5zF2bSx7CPy-"
      },
      "outputs": [],
      "source": [
        "!pip install pymc_marketing\n",
        "!pip install numpy\n",
        "!pip install matplotlib\n",
        "!pip install scipy\n",
        "!pip install seaborn\n",
        "!pip install pymc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3_7NA59CQSo"
      },
      "outputs": [],
      "source": [
        "import pymc_marketing as pmc\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pymc as pm\n",
        "from scipy.stats import beta, gamma, halfnorm, norm\n",
        "import seaborn as sns\n",
        "from pymc_marketing.mmm.components.adstock import GeometricAdstock\n",
        "from pymc_marketing.mmm.components.saturation import LogisticSaturation\n",
        "from pymc_marketing.mmm import MMM\n",
        "from sklearn.preprocessing import MaxAbsScaler\n",
        "from pymc_marketing.mmm.transformers import logistic_saturation\n",
        "from pymc_marketing.mmm.transformers import geometric_adstock\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M30fntqg7flF"
      },
      "source": [
        "Reads the Data, and artificially inflates Sales data since in the original data Sales was less than channel cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MXgtJiCCQVo"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(\"C:/Users/sahil/Downloads/advertising.csv\")\n",
        "data[\"Trend\"] = [x for x in range(len(data[\"TV\"]))]\n",
        "data[\"sales\"] = data['sales'] * 50\n",
        "data.head(n = 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-PFenGB76bB"
      },
      "source": [
        "*  Plot the different columns to undertsand the data and Trend\n",
        "*  The model tries to calculate the baseline  which is a combination of Trend and Seasonality\n",
        "*  Even though the model has inbuilt functionality of calculating Trend, it can also be added as a control column\n",
        "*  The Trend created by model has a prior of Normal distribution with mean as 0 and standard deviation as 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKXUi7U9CQYE"
      },
      "outputs": [],
      "source": [
        "\n",
        "colors = ['red', 'green', 'blue', 'orange', 'yellow']\n",
        "for i in range(len(data.columns)):\n",
        "  plt.figure(figsize=(4, 4))\n",
        "  plt.plot(data[data.columns[i]], marker='o', label=data.columns[i], color=colors[i])\n",
        "  plt.xlabel('Weeks')\n",
        "  plt.ylabel('Spend')\n",
        "  plt.title('Trend')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "  plt.show()\n",
        "  plt.clf()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QEzKdWH82Ht"
      },
      "source": [
        "\n",
        "\n",
        "*   Heatmap help us understand correlation of the different channel metrics\n",
        "*   It is completely normal that there is a high corr since multiple teams can increase or decrease their channel spends simultaneously\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUY9Ux-2CQaV"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(4, 4))\n",
        "sns.heatmap(data[['TV', 'radio', 'newspaper', 'sales']].corr(), annot=True, cmap='coolwarm', vmin=-1, vmax=1)\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rsKY1V39UUi"
      },
      "source": [
        "\n",
        "\n",
        "*   You need to also pass in the Time as one of the columns which is used by model to predict seasonlity\n",
        "*   MMM model uses fourier series which is a mix of sine and cosine to predict seasonlity\n",
        "*   You can pass on Yearly seasonlity with default number of seasons as 4-5\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mo1pCqoXCQcz"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime, timedelta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czA6UjunISzB"
      },
      "outputs": [],
      "source": [
        "start_date = datetime(2024, 1, 1)\n",
        "data[\"w\"] = [start_date + timedelta(weeks= i) for i in range(len(data[\"Trend\"]))]\n",
        "data.head(n = 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbETsEmU-Lta"
      },
      "source": [
        "***The data fed to model is NOT standardised so that the different features can be learnt with scales for the analysis***\n",
        "\n",
        "The input data consists of:\n",
        "1. control columns - Which have a direct impact on final output. Control output are multiplied with coefficients known as gama to calculate their actual output\n",
        "2. channel columns - Channel columns are transformed using adstock and saturation and also multipled by gama to understand their actual aoutput\n",
        "3. Output - Sales\n",
        "4. Date columns - Date could be in weekly or daily\n",
        "\n",
        "The contole columns consist of\n",
        "1. Trend\n",
        "2. Any external output of environment - such as festivals, covid etc. It can be representes as a 0/1\n",
        "3. Impact due to competitors - again can be represented as zero or 1\n",
        "4. Trend can be added here and the model has inherent capability of calculating Trend using normal distribution\n",
        "\n",
        "Similar to other models, the data is split in test and control, to see if the predicited coefficients matches te output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeVjUD-6IS12"
      },
      "outputs": [],
      "source": [
        "# set date column\n",
        "date_col = \"w\"\n",
        "\n",
        "# set outcome column\n",
        "y_col = \"sales\"\n",
        "\n",
        "# set marketing variables\n",
        "channel_cols = [\"TV\",\n",
        "                \"radio\",\n",
        "                \"newspaper\"]\n",
        "\n",
        "# set control variables\n",
        "control_cols = [\"Trend\"]\n",
        "\n",
        "\n",
        "# split data into features and target\n",
        "X = data[[date_col] + channel_cols + control_cols]\n",
        "y = data[y_col]\n",
        "print(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-7EQbcCIS4e"
      },
      "outputs": [],
      "source": [
        "# create train and test indices\n",
        "\n",
        "test_len = 8\n",
        "train_idx = slice(0, len(data) - test_len)\n",
        "out_of_time_idx = slice(len(data) - test_len, len(data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJx6wwCzh-cu"
      },
      "outputs": [],
      "source": [
        "train_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhSArFOHAgQe"
      },
      "source": [
        "Creating a dummy model to show default priors\n",
        "\n",
        "**Definition of coefficents**\n",
        "1. intercept - The baseline level of sales or target variable in the absence of\n",
        "any marketing spend or other variables. It sets the starting point for the model.\n",
        "2. likelihood - When you increase the focus on the likelihood, the model relies more heavily on the observed data and less on the priors. This means the model will be more data-driven, allowing the observed outcomes to have a stronger influence on the parameter estimates\n",
        "3. gamma control - Control variables that account for external factors, such as macroeconomic conditions, holidays, or other non-marketing variables that might influence sales.\n",
        "4. gamma fourier - Fourier terms used to model seasonality in the data, capturing recurring patterns or cycles in sales.\n",
        "5. adstock alpha - Controls the adstock effect, determining how much the impact of marketing spend decays over time.\n",
        "saturation lamda - Defines the steepness of the saturation curve, determining how quickly diminishing returns set in as marketing spend increases.\n",
        "6. saturation beta - The marketing spend coefficient, which measures the direct effect of marketing spend on the target variable (e.g. sales).\n",
        "\n",
        "**Why some specific deafaults are chosen for coefficients**\n",
        "1. Normal: For parameters where we expect values to cluster around a mean.Since trend and external factor can be both positive or negative, Normal destribution is used for this sceanrio\n",
        "\n",
        "2. Half-Normal: For parameters where we want to enforce positivity.\n",
        "\n",
        "3. **Adstock** - Adstock reflects the idea that the influence of a marketing activity is delayed and builds up over time. The **adstock alpha (the decay rate)** controls how quickly the effect diminishes over time, determining how long the impact of the marketing activity continues to influence sales. A beta distribution is used as a prior for adstock alpha. We typically constrain adstock alpha values between 0 and 1, making the beta distribution a sensible choice. Specifically, using a beta(1, 3) prior for adstock alpha reflects the belief that, in most cases, the decay rate should be relatively high, meaning the effect of marketing activities wears off quickly.\n",
        "\n",
        "4. **Saturation lamda** - As we increase marketing spend, it’s incremental impact of sales slowly starts to reduce – This is known as saturation. Saturation lamda controls the steepness of the saturation curve, determining how quickly diminishing returns set in.\n",
        "A gamma distribution is used as a prior for saturation lambda.\n",
        "\n",
        "5. **Saturation beta** - Saturation beta corresponds to the marketing channel coefficient, measuring the impact of marketing spend. The half-normal prior is used as it enforces positivity which is a very reasonable assumption e.g. marketing shouldn’t have a negative effect in any scenario\n",
        "\n",
        "6. Beta: For parameters which are constrained between 0 and 1.\n",
        "\n",
        "7. Gamma: For parameters that are positive and skewed.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6L0M1LLIS65"
      },
      "outputs": [],
      "source": [
        "dummy_model = MMM(\n",
        "    date_column=\"\",\n",
        "    channel_columns=[\"\"],\n",
        "    adstock= GeometricAdstock(l_max=4),\n",
        "    saturation= LogisticSaturation(),\n",
        ")\n",
        "dummy_model.default_model_config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0SQrXVZdEmbm"
      },
      "source": [
        "1. This could be used to see all the arguments avaialble in MMM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwdcI8zcMC7m"
      },
      "outputs": [],
      "source": [
        "import inspect\n",
        "print(inspect.signature(MMM.__init__))\n",
        "temp = str(inspect.signature(MMM.__init__))\n",
        "temp = temp.replace(\"(\", '').replace(\")\", \"\")\n",
        "for i in temp.split(\",\"):\n",
        "  print(i, \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhl9CD_tE7Pe"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "mmm = MMM(\n",
        "    target='sales',\n",
        "    date_column='week',\n",
        "    channel_columns=['TV', 'Digital', 'Radio'],\n",
        "    control_columns=['price', 'promo'],\n",
        "    adstock=GeometricAdstock(l_max=8),\n",
        "    saturation=LogisticSaturation(),\n",
        "    beta_prior=lambda shape: Normal.dist(mu=0, sigma=0.3, shape=shape),\n",
        "    prior_sigma=HalfNormal.dist(sigma=1),\n",
        "    adstock_params_prior=lambda n: Beta.dist(alpha=2, beta=2, shape=n),\n",
        "    saturation_params_prior=lambda n: HalfNormal.dist(sigma=1, shape=n)\n",
        "    yearly_seasonality=4\n",
        ")\n",
        "```\n",
        "\n",
        "1. Most of the coefficients are default configurations are default in nature\n",
        "2. The configurations can be added to make a distribution more strict\n",
        "3. Further, you can provide different priors for different channels in distribution\n",
        "\n",
        "```\n",
        "beta_prior=lambda shape: pm.Normal.dist(mu=np.zeros(shape),\n",
        "                                        sigma=np.array([0.2, 0.5, 0.8]),\n",
        "                                        shape=shape)\n",
        "```\n",
        "4. yearly_seasonality created fouries series for seasonality in the analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWyW1QVvIS9a"
      },
      "outputs": [],
      "source": [
        "mmm_default = MMM(\n",
        "    adstock=GeometricAdstock(l_max=8),\n",
        "    saturation=LogisticSaturation(),\n",
        "    date_column=date_col,\n",
        "    channel_columns=channel_cols,\n",
        "    control_columns=control_cols,\n",
        "    yearly_seasonality=4\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kWVg-xBVIS_u"
      },
      "outputs": [],
      "source": [
        "fit_kwargs = {\n",
        "    \"tune\": 1_000,\n",
        "    \"chains\": 4,\n",
        "    \"draws\": 1_000,\n",
        "    \"target_accept\": 0.9,\n",
        "}\n",
        "\n",
        "mmm_default.fit(X[train_idx], y[train_idx], **fit_kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuVfX5YwI61V"
      },
      "source": [
        "It helps us understand if there were any coefficietns which didnt converge to a mean and thus were not calculated properly under contrains in this sceanrio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wUZh1XugITCn"
      },
      "outputs": [],
      "source": [
        "mmm_default.idata[\"sample_stats\"][\"diverging\"].sum().item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8WPKaRCITFx"
      },
      "outputs": [],
      "source": [
        "import arviz as az"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBVGAUQPFqbQ"
      },
      "source": [
        "\n",
        "\n",
        "$$Y_t = \\beta_0 + (\\beta_{Trend} \\cdot \\text{Trend}_t) + (\\sum \\beta_{Season} \\cdot \\text{Seasonality}_t) + (\\sum \\beta_{Media} \\cdot \\text{Media Transformed}_t) + \\epsilon_t$$\n",
        "\n",
        "1. $$\\beta_0$$ - intercept or baseline sales that is there due to demand of a product\n",
        "2. Baseline sales - $$\\beta_0 + (\\beta_{Trend} \\cdot \\text{Trend}_t) + (\\sum \\beta_{Season} \\cdot \\text{Seasonality}_t)$$\n",
        "3. The different will have different channel coefficients\n",
        "4. y_sigma\t- refers to noise in the model and is represented as \\epsilon_t$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCEkM6yNITHj"
      },
      "outputs": [],
      "source": [
        "az.summary(\n",
        "    data=mmm_default.fit_result,\n",
        "    var_names=[\n",
        "        \"intercept\",\n",
        "        \"y_sigma\",\n",
        "        \"saturation_beta\",\n",
        "        \"saturation_lam\",\n",
        "        \"adstock_alpha\",\n",
        "        \"gamma_control\",\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jt6oWGkjTfXm"
      },
      "outputs": [],
      "source": [
        "results = az.summary(\n",
        "    data=mmm_default.fit_result,\n",
        "    var_names=[\n",
        "        \"intercept\",\n",
        "        \"y_sigma\",\n",
        "        \"saturation_beta\",\n",
        "        \"saturation_lam\",\n",
        "        \"adstock_alpha\",\n",
        "        \"gamma_control\",\n",
        "    ],\n",
        ")\n",
        "results.loc[\"adstock_alpha[TV]\", \"mean\",]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clOgS1xwKbrJ"
      },
      "source": [
        "To understand the distribution of different calculated coefficients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwSvIbmZITKF"
      },
      "outputs": [],
      "source": [
        "_ = az.plot_trace(\n",
        "    data=mmm_default.fit_result,\n",
        "    var_names=[\n",
        "        \"intercept\",\n",
        "        \"y_sigma\",\n",
        "\n",
        "        \"saturation_beta\",\n",
        "        \"saturation_lam\",\n",
        "        \"adstock_alpha\",\n",
        "        \"gamma_control\",\n",
        "    ],\n",
        "    compact=True,\n",
        "    backend_kwargs={\"figsize\": (12, 10), \"layout\": \"constrained\"},\n",
        ")\n",
        "plt.gcf().suptitle(\"Model Trace\", fontsize=16);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQ9pFN02ITMM"
      },
      "outputs": [],
      "source": [
        "mmm_default.sample_posterior_predictive(X[train_idx], extend_idata=True, combined=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWW-SI8FCQfU"
      },
      "outputs": [],
      "source": [
        "mmm_default.plot_posterior_predictive(original_scale=True, figsize=(12, 6));\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cymInIV01DAO"
      },
      "source": [
        "The below graph is for distribution of noise. Noise should have a mean around zero and have a normal distribution as below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOALyKYCCQhu"
      },
      "outputs": [],
      "source": [
        "mmm_default.plot_errors(original_scale=True);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nirv6hDCCQkc"
      },
      "outputs": [],
      "source": [
        "errors = mmm_default.get_errors(original_scale=True)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "az.plot_dist(\n",
        "    errors, quantiles=[0.25, 0.5, 0.75], color=\"C3\", fill_kwargs={\"alpha\": 0.7}, ax=ax\n",
        ")\n",
        "ax.axvline(x=0, color=\"black\", linestyle=\"--\", linewidth=1, label=\"zero\")\n",
        "ax.legend()\n",
        "ax.set(title=\"Errors Posterior Distribution\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyFozJ0QTQGv"
      },
      "source": [
        "How trained model output is against test values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9L2-SI_SomK"
      },
      "outputs": [],
      "source": [
        "y_out_of_sample = mmm_default.sample_posterior_predictive(\n",
        "    X_pred=X[out_of_time_idx], extend_idata=False, include_last_observations=True\n",
        ")\n",
        "\n",
        "def plot_in_sample(X, y, ax, n_points: int = 15):\n",
        "    (\n",
        "        y.to_frame()\n",
        "        .set_index(X[date_col])\n",
        "        .iloc[-n_points:]\n",
        "        .plot(ax=ax, marker=\"o\", color=\"black\", label=\"actuals\")\n",
        "    )\n",
        "    return ax\n",
        "\n",
        "def plot_out_of_sample(X_out_of_sample, y_out_of_sample, ax, color, label):\n",
        "    y_out_of_sample_groupby = y_out_of_sample[\"y\"].to_series().groupby(\"date\")\n",
        "\n",
        "    lower, upper = quantiles = [0.025, 0.975]\n",
        "    conf = y_out_of_sample_groupby.quantile(quantiles).unstack()\n",
        "    ax.fill_between(\n",
        "        X_out_of_sample[date_col].dt.to_pydatetime(),\n",
        "        conf[lower],\n",
        "        conf[upper],\n",
        "        alpha=0.25,\n",
        "        color=color,\n",
        "        label=f\"{label} interval\",\n",
        "    )\n",
        "\n",
        "    mean = y_out_of_sample_groupby.mean()\n",
        "    mean.plot(ax=ax, marker=\"o\", label=label, color=color, linestyle=\"--\")\n",
        "    ax.set(ylabel=\"Original Target Scale\", title=\"Out of sample predictions for MMM\")\n",
        "    return ax\n",
        "\n",
        "_, ax = plt.subplots()\n",
        "plot_in_sample(X, y, ax=ax, n_points=len(X[out_of_time_idx])*3)\n",
        "plot_out_of_sample(\n",
        "    X[out_of_time_idx], y_out_of_sample, ax=ax, label=\"out of sample\", color=\"C0\"\n",
        ")\n",
        "ax.legend(loc=\"upper left\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cToNkm9VODX"
      },
      "source": [
        "The adstock coefficients for TV and Radio is very less which states the the impact of marketing channel have a very less carry over\n",
        "This is against the usual impact of channels\n",
        "1. TV / Broad-reach broadcast - Typical α: 0.6 – 0.9 (long memory), Suggested prior: Beta(5, 2) → mean ≈ 0.714\n",
        "2. Radio - Typical α: 0.2 – 0.5, Suggested prior: Beta(2, 3) → mean = 0.4\n",
        "3. Display / Social (brand-focused) - Typical α: 0.1 – 0.4; Suggested prior: Beta(2, 5) → mean ≈ 0.286\n",
        "4. Paid Search (search / SEM): Typical α: 0.01 – 0.15, Suggested prior: Beta(1.5, 10) → mean ≈ 0.13\n",
        "5. Email / Direct (campaigns/promos) - Typical α: 0 – 0.2: Suggested prior: Beta(1, 4) → mean = 0.20 (or Beta(1,6) for mean ≈ 0.14)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wshfuoOkSoo5"
      },
      "outputs": [],
      "source": [
        "fig = mmm_default.plot_channel_parameter(param_name=\"adstock_alpha\", figsize=(9, 5))\n",
        "ax = fig.axes[0]\n",
        "ax.axvline(x=results.loc[\"adstock_alpha[TV]\", \"mean\"], color=\"C0\", linestyle=\"--\", label=r\"$alpha_1$\")\n",
        "ax.axvline(x=results.loc[\"adstock_alpha[radio]\", \"mean\"], color=\"C1\", linestyle=\"--\", label=r\"$alpha_2$\")\n",
        "ax.axvline(x=results.loc[\"adstock_alpha[newspaper]\", \"mean\"], color=\"C2\", linestyle=\"--\", label=r\"$alpha_3$\")\n",
        "ax.legend(loc=\"upper right\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lakDZcJzXwlq"
      },
      "source": [
        "Even though the data is fed as is in the model, but the internal algorithm normalise the data to calculate saturation coefficients\n",
        "Broad-reach channels (TV, Brand Video)\n",
        "\n",
        "Typical behavior: saturates late — incremental responses continue at higher spends.\n",
        "\n",
        "**Practical default ranges & priors (for normalized inputs)**\n",
        "1. Broad-reach channels (TV, Brand Video), Typical behavior: saturates late — incremental responses continue at higher spends.\n",
        "\n",
        "    β (half-sat): typical range 0.6 – 2.0, Prior: LogNormal(mu=0, sigma=0.6) → median ≈ 1.0 (covers 0.5–2 comfortably)\n",
        "\n",
        "    λ (steepness): 0.7 – 1.5, Prior: Gamma(2, 1) (mean 2 → you can use Gamma(1.5, 1) or LogNormal(log(1), 0.5) for ~1)\n",
        "\n",
        "2. Mid-reach / repeated-display (OOH, Display brand, Social brand creatives, Typical behavior: moderate saturation\n",
        "\n",
        "    β: 0.3 – 1.0, Prior: LogNormal(mu=-0.3, sigma=0.6) → median ≈ 0.74\n",
        "\n",
        "    λ: 0.6 – 1.2, Prior: Gamma(2, 1) or LogNormal(log(1), 0.7)\n",
        "\n",
        "3. Lower-latency channels (Radio, Some social direct-response), Typical behavior: saturates earlier than TV\n",
        "\n",
        "    β: 0.2 – 0.6, Prior: LogNormal(mu=-1, sigma=0.7) → median ≈ 0.37\n",
        "\n",
        "    λ: 0.5 – 1.0, Prior: Gamma(1.5, 1) or LogNormal(log(0.8), 0.6)\n",
        "\n",
        "4. High-immediacy / performance channels (Paid Search, Affiliate), Typical behavior: strong immediate effect → quick saturation (low β)\n",
        "\n",
        "    β: 0.01 – 0.2 (often very small after normalisation), Prior: LogNormal(mu=-2.5, sigma=1.0) → median ≈ 0.08\n",
        "\n",
        "    λ: 0.3 – 1.0 (often <1 for smooth concave response), Prior: Gamma(1.2, 1) or LogNormal(log(0.6), 0.7)\n",
        "\n",
        "4. Email / CRM / Promotional blasts, Typical behavior: strong spike + quick tail\n",
        "\n",
        "    β: 0.05 – 0.3, Prior: LogNormal(mu=-2, sigma=0.8) → median ≈ 0.14\n",
        "\n",
        "    λ: 0.4 – 1.0, Print / Newspaper / Flyers (if used)\n",
        "\n",
        "5. Print / Newspaper / Flyers (if used): Typical behavior: often small effect, saturates quickly if at all,\n",
        "\n",
        "    β: 0.05 – 0.4 (high uncertainty), Prior: LogNormal(mu=-1.5, sigma=1.0)\n",
        "\n",
        "    λ: 0.4 – 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ocx9U91qWS0H"
      },
      "outputs": [],
      "source": [
        "fig = mmm_default.plot_channel_parameter(param_name=\"saturation_lam\", figsize=(9, 5))\n",
        "ax = fig.axes[0]\n",
        "ax.axvline(x=saturation_lamdas[0], color=\"C0\", linestyle=\"--\", label=r\"$lambda_1$\")\n",
        "ax.axvline(x=saturation_lamdas[1], color=\"C1\", linestyle=\"--\", label=r\"$lambda_2$\")\n",
        "ax.axvline(x=saturation_lamdas[2], color=\"C2\", linestyle=\"--\", label=r\"$lambda_3$\")\n",
        "ax.legend(loc=\"upper right\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAfJnGwSJg1D"
      },
      "source": [
        "When you ask Pymc-Marketing to show the final channel contribution share (e.g., using mmm.plot_components_contributions()), it typically does the following:\n",
        "1. Calculates the Total Incremental Sales (the part of sales above the baseline) for every MCMC sample.\n",
        "2. Calculates the Total Contribution for each individual channel (summing the $\\text{Contribution}_{m, t, i}$ over all time periods $t$) for every MCMC sample.\n",
        "3. Computes the Contribution Share for each channel for every sample by dividing the channel's total contribution by the total incremental sales.\n",
        "4. Summarizes the Distribution to present the final result, usually showing the mean (or median) of the contribution share distribution, along with the credible interval (e.g., 95% HDI)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9z0IgGToctpe"
      },
      "outputs": [],
      "source": [
        "channel_contrib\n",
        "posterior_samples = channel_contrib.stack(draws=(\"chain\", \"draw\")).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXpoPQ12iJ7r"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mst35k6iJ-K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Pn0nAxUiKAm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b87cv58ZiKDD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POG299KOiKFk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pcw8OUPWiKIG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-w9r0QMiKJ_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9wVKCAjiKMh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-VOtuQ3CQpk"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDd_w3pPCQsQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}