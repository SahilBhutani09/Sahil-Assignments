{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e35f10c",
   "metadata": {},
   "source": [
    "Frequentist Approach relies on classification models\n",
    "such Logistics Regression, Decision Trees, Random Forest, XG Boost to find the exact coefficietns value for customer classification\n",
    "\n",
    "For Customer churn, the output should be binary i.e. whether customer churned or not. \n",
    "\n",
    "Since the data is related to customer subscription, customer needs to explicitly sign out and thus we have clear signal that the customer has churned in contarast to ecommerce where depending upon customer behaviour, we get a tendancy that customer might have churned and thus bayesian churn models are more applicable in such scenarios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605e7158",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\")\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087955e4",
   "metadata": {},
   "source": [
    "#Add Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5745aa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inputData =  pd.read_csv('C:/Users/sahil/Desktop/Case/advance.csv')\n",
    "#training_data = inputData.sample(frac=0.8, random_state=25)\n",
    "#testing_data = inputData.drop(training_data.index)\n",
    "#print(inputData.columns)\n",
    "#del inputData['Not Cancelled 2016 Subscription']\n",
    "#del inputData['ACCT_ID']\n",
    "#del inputData['USERS_2016']\n",
    "#del inputData['Total Revenue 2015']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c489055",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "inputData['En_FIRST_YR_CUSTOMER'] = label_encoder.fit_transform(inputData['FIRST_YR_CUSTOMER'] )\n",
    "inputData['En_COUNTRY'] = label_encoder.fit_transform(inputData['COUNTRY'] )\n",
    "inputData['En_ACCT_MGR_STATUS'] = label_encoder.fit_transform(inputData['ACCT_MGR_STATUS'] )\n",
    "inputData['En_ACCT_REVENUE_CAT'] = label_encoder.fit_transform(inputData['ACCT_REVENUE_CAT'] )\n",
    "inputData['En_ACCT_EMPLOYEE_CAT'] = label_encoder.fit_transform(inputData['ACCT_EMPLOYEE_CAT'] )\n",
    "inputData['En_ACCT_TYPE'] = label_encoder.fit_transform(inputData['ACCT_TYPE'] )\n",
    "\n",
    "inputData.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651ec73b",
   "metadata": {},
   "source": [
    "#Normalise the data since it is a model for logistics regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d0435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = ['MEDICAL_REVENUE_2015',\n",
    "       'SCIENTIFIC_REVENUE_2015', 'TECHNICAL_REVENUE_2015',\n",
    "       'MEDICAL_NO_SESSIONS_2015', 'SCIENTIFIC_NO_SESSIONS_2015',\n",
    "       'TECHNICAL_NO_SESSIONS_2015', 'USERS_2015', 'En_FIRST_YR_CUSTOMER', 'En_COUNTRY',\n",
    "       'En_ACCT_MGR_STATUS', 'En_ACCT_REVENUE_CAT', 'En_ACCT_EMPLOYEE_CAT',\n",
    "       'En_ACCT_TYPE']\n",
    "X = inputData[cols]\n",
    "y = inputData.loc[:, inputData.columns == 'Cancelled 2016 subscription']\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "norm = MinMaxScaler()\n",
    "X_norm = norm.fit_transform(X)\n",
    "X_norm = pd.DataFrame(X_norm, columns = X.columns)\n",
    "X_norm.head()\n",
    "\n",
    "X_norm.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60c9d59",
   "metadata": {},
   "source": [
    "#apply SelectKBest class to extract top 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f77c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=chi2, k=5)\n",
    "fit = bestfeatures.fit(X_norm,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X_norm.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features\n",
    "featureScores[featureScores.Score > featureScores.Score.mean()]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b902cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cols = featureScores[featureScores.Score > featureScores.Score.mean()].Specs\n",
    "X = X_norm[cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e70000a",
   "metadata": {},
   "source": [
    "We need to Balance the data using SMOT so that there is no bias for Churned out customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c4022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "os = SMOTE(random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "columns = X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf2679f",
   "metadata": {},
   "source": [
    "#Logistics Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a885d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_std = LogisticRegression()\n",
    "info = lr_std.fit(X_train, y_train)\n",
    "y_pred = lr_std.predict(X_test)\n",
    "print('Accuracy of logistic regression on test set with standardized features: {:.2f}'.format(lr_std.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacd4019",
   "metadata": {},
   "source": [
    "#Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaa757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import statsmodels.api as sm\n",
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit(maxiter=2000)\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c8bc0b",
   "metadata": {},
   "source": [
    "#Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3877081",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = X_norm\n",
    "#implementing train-test-split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=66)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e5cc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# random forest model creation\n",
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)\n",
    "# predictions\n",
    "rfc_predict = rfc.predict(X_test)\n",
    "f_i = list(zip(X.columns,rfc.feature_importances_))\n",
    "f_i.sort(key = lambda x : x[1])\n",
    "plt.barh([x[0] for x in f_i],[x[1] for x in f_i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f93a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "rfc_cv_score = cross_val_score(rfc, X, y, cv=10, scoring=\"roc_auc\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bad4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f913e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=200, max_depth=140, max_features='sqrt')\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc_predict = rfc.predict(X_test)\n",
    "rfc_cv_score = cross_val_score(rfc, X, y, cv=10, scoring='roc_auc')\n",
    "print(\"=== Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores ===\")\n",
    "print(rfc_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_cv_score.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d97536",
   "metadata": {},
   "source": [
    "#Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8da02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "ada_classifier=AdaBoostClassifier()\n",
    "ada_classifier.fit(X_train, y_train)\n",
    "ytest_pred = ada_classifier.predict_proba(X_test)\n",
    "print('Adaboost test roc-auc: {}'.format(roc_auc_score(y_test, ytest_pred[:,1])))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66142084",
   "metadata": {},
   "source": [
    "#Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a8d5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import tree\n",
    "\n",
    "X = inputData.loc[:, inputData.columns != 'Cancelled 2016 subscription']\n",
    "\n",
    "X = X[['MEDICAL_REVENUE_2015', 'TECHNICAL_REVENUE_2015',\n",
    "       'MEDICAL_NO_SESSIONS_2015', 'USERS_2015', 'FIRST_YR_CUSTOMER']]\n",
    "\n",
    "y = inputData.loc[:, inputData.columns == 'Cancelled 2016 subscription']\n",
    "\n",
    "regr = DecisionTreeRegressor(max_depth=4, random_state=1234)\n",
    "model = regr.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8153bc47",
   "metadata": {},
   "source": [
    "#Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83cd7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "\n",
    "X = inputData.loc[:, inputData.columns != 'Cancelled 2016 subscription']\n",
    "\n",
    "X = X[['MEDICAL_REVENUE_2015', 'TECHNICAL_REVENUE_2015',\n",
    "       'MEDICAL_NO_SESSIONS_2015', 'USERS_2015', 'FIRST_YR_CUSTOMER']]\n",
    "\n",
    "y = inputData.loc[:, inputData.columns == 'Cancelled 2016 subscription']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "regr = DecisionTreeRegressor(max_depth=4, random_state=1234)\n",
    "model = regr.fit(X_train, y_train)\n",
    "\n",
    "Decision_tree_predict = model.predict(X_test)>0.5\n",
    "Decision_tree_predict\n",
    "#print(classification_report(y_test, Decision_tree_predict))\n",
    "metrics.accuracy_score(y_test, Decision_tree_predict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb596284",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(100,100))\n",
    "_ = tree.plot_tree(regr, feature_names= ['MEDICAL_REVENUE_2015', 'TECHNICAL_REVENUE_2015',\n",
    "       'MEDICAL_NO_SESSIONS_2015', 'USERS_2015', 'En_FIRST_YR_CUSTOMER']\n",
    "                   , filled=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c9a087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc77633",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d901ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1c623a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
